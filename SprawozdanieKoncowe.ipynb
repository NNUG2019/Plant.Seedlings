{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie z laboratorium - sieci neuronowe\n",
    "\n",
    "Temat: Plant Seedlings Classification\n",
    "\n",
    "Skład grupy: Julia Blicharska, Weronika Deleżuch, Aleksandra Zalewska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opis zadania\n",
    "\n",
    "Celem jest stworzenie klasyfikatora, który będzie rozpoznawał gatunek sadzonki na podstawie zdjęcia i przypisywał mu odpowiednią nazwę.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane\n",
    "\n",
    "Danymi, nad którymi pracujemy jest zestaw treningowy i zestaw testowy zdjęć sadzonek roślin na różnych etapach rozwoju.\n",
    "\n",
    "Każdy obraz ma nazwę pliku, która jest jego unikalnym identyfikatorem.\n", 
    "\n",
    "Zestaw danych obejmuje 12 gatunków roślin. Lista gatunków jest następująca:\n",
    "\n",
    "• Black-grass (Konwalnik płaskopędowy)\n", 
    "\n",
    "• Charlock (Gorczyca polna)\n",
    "\n",
    "• Cleavers (Przytulia czepna)\n",
    "\n",
    "• Common Chickweed (Gwiazdnica pospolita)\n",
    "\n",
    "• Common wheat (Pszenica zwyczajna)\n",
    "\n",
    "• Fat Hen (Komosa biała)\n",
    "\n",
    "• Loose Silky-bent (Miotła zbożowa)\n",
    "\n",
    "• Maize (Kukurydza zwyczajna)\n",
    "\n",
    "• Scentless Mayweed (Maruna nadmorska)\n",
    "\n",
    "• Shepherds Purse (Tasznik pospolity)\n",
    "\n",
    "• Small-flowered Cranesbill (Bodziszek drobny)\n",
    "\n",
    "• Sugar beet (Burak cukrowy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza danych\n",
    "\n",
    "Dane treningowe.\n",
    "\n",
    "Mamy 4763 zdjęć sadzonek, które są podzielone na foldery pod względem gatunków.\n",
    "\n",
    "Ilość zdjęć w każdym z folderów:\n",
    "\n",
    "• Black-grass (Konwalnik płaskopędowy)  - 263\n",
    "\n",
    "• Charlock (Gorczyca polna) - 390\n",
    "\n",
    "• Cleavers (Przytulia czepna) - 287\n",
    "\n",
    "• Common Chickweed (Gwiazdnica pospolita) - 611\n",
    "\n",
    "• Common wheat (Pszenica zwyczajna) - 221\n",
    "\n",
    "• Fat Hen (Komosa biała) - 475\n",
    "\n",
    "• Loose Silky-bent (Miotła zbożowa) - 654\n",
    "\n",
    "• Maize (Kukurydza zwyczajna) - 221\n",
    "\n",
    "• Scentless Mayweed (Maruna nadmorska) - 516\n",
    "\n",
    "• Shepherds Purse (Tasznik pospolity) - 231\n",
    "\n",
    "• Small-flowered Cranesbill (Bodziszek drobny) - 495\n",
    "\n",
    "• Sugar beet (Burak cukrowy) - 386\n",
    "\n",
    "Dane testowe.\n",
    "\n",
    "W tej grupie znajduje się 794 zdjęć. Będziemy na nich sprawdzać czy nasz model został dobrze wytrenowany i czy sieć działa poprawnie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Do naszego zadania wybrałyśmy sieć konwolucyjną - CNN. Jest to struktura, która bardzo dobrze sprawdza się w zadaniach dotyczących rozpoznawania i klasyfikacji obrazów. Dzieje się tak, ponieważ głębokie sieci konwolucyjne (CNN) potrafią stopniowo filtrować różne części danych uczących i wyostrzać ważne cechy w procesie dyskryminacji wykorzystanym do rozpoznawania lub klasyfikacji wzorców. Pozwala to na znajdowanie najważniejszych elementów na danym zdjęciu sadzonki i dobrym dopasowaniu gatunku rośliny.\n",
    "\n",
    "### Działanie\n",
    "\n",
    "Wczytanie danych.\n",
    "\n",
    "Oczyszczamy zdjęcia usuwając z nich szum tak, aby zostały tylko elementy zielone.\n",
    "\n",
    "Przybliżamy obrazki, wyostrzamy je oraz dzielimy.\n",
    "\n"
   ]
  },
  {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for filename in filenames:\n",
    " print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\n",
    "height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\n",
    "horizontal_flip=True, fill_mode="nearest")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(aug.flow(X_train, Y_train, batch_size=BATCH_SIZE), \\n",
    "validation_data=(X_val, Y_val), \\n",
    " steps_per_epoch=len(X_train) // BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobranie bibliotek.\n",
    "\n",
    "Importujemy pakiety niezbędne do stworzenia sieci.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use("Agg")\n",
    "plt.style.use("ggplot")\n",
    "plt.figure(figsize=(20,12)),\n",
    "plt.plot(np.arange(0, EPOCHS), history.history["loss"], label="train_loss")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history["val_loss"], label="val_loss")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history["accuracy"], label="train_acc")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history["val_accuracy"], label="val_acc")\n",
    "plt.title("Training Loss and Accuracy on  crop classification")\n",
    "plt.xlabel("Epoch Number")\n",
    "plt.ylabel("Loss/Accuracy")\n",
    "plt.legend(loc="lower left")\n",
    "plt.show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras.layers.core import Activation, Flatten, Dense \n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
    "from keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import random \n",
    "import os \n",
    "import sys \n",
    "import cv2 \n",
    "from keras.utils import to_categorical \n",
    "import matplotlib.pyplot as plt"
   ]
  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadanie klas zdjęciom.\n",
    "\n",
    "Przyporządkowuje to numer do gatunku rośliny, a po rozpoznaniu rośliny utworzona sieć da nam jej nazwę.\n",
    "\n",
    "Ustawienie jednakowych rozmiarów dla wszystkich zdjęć.\n",
    "\n",
    "Model i dane treningowe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "\n",
    "Udało nam się stworzyć model, który rozpoznaje gatunek sadzonki widocznej na zdjęciu i podaje jego nazwę. Jest nauczony rozpoznawać aż 12 gatunków roślin na różnych etapach rozwoju. Po przetestowaniu modelu mamy pewność, że jest on dokładny i nie powinien robić wielu błędów przy klasyfikacji roślin.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
